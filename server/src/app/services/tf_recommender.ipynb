{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define user and item data\n",
    "# user_data = [\n",
    "#     {\n",
    "#         \"user_id\": 1,\n",
    "#         \"interests\": [\"hành động\", \"adventure\"],\n",
    "#         \"liked\": [102, 103]\n",
    "#     },\n",
    "#     {\n",
    "#         \"user_id\": 2,\n",
    "#         \"interests\": [\"comedy\", \"romance\"],\n",
    "#         \"liked\": [102, 105]\n",
    "#     },\n",
    "#     {\n",
    "#         \"user_id\": 3,\n",
    "#         \"interests\": [\"science fiction\"],\n",
    "#         \"liked\": [104]\n",
    "#     }\n",
    "# ]\n",
    "\n",
    "# item_data = [\n",
    "#     {\n",
    "#         \"item_id\": 101,\n",
    "#         \"genres\": [\"hành động\", \"adventure\"]\n",
    "#     },\n",
    "#     {\n",
    "#         \"item_id\": 102,\n",
    "#         \"genres\": [\"comedy\", \"romance\"]\n",
    "#     },\n",
    "#     {\n",
    "#         \"item_id\": 103,\n",
    "#         \"genres\": [\"hành động\", \"adventure\"]\n",
    "#     },\n",
    "#     {\n",
    "#         \"item_id\": 104,\n",
    "#         \"genres\": [\"science fiction\"]\n",
    "#     },\n",
    "#     {\n",
    "#         \"item_id\": 105,\n",
    "#         \"genres\": [\"comedy\"]\n",
    "#     }\n",
    "# ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load user interests from JSON (replace 'your_interests.json' with your JSON file)\n",
    "with open('../data/users.json', 'r', encoding='utf-8') as json_file:\n",
    "    user_data = json.load(json_file)\n",
    "\n",
    "# Load item data from JSON (replace 'your_items.json' with your JSON file)\n",
    "with open('../data/campaigns.json', 'r', encoding='utf-8') as json_file:\n",
    "    item_data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: 0, 2: 1, 3: 2}\n"
     ]
    }
   ],
   "source": [
    "# Create mappings for user and item IDs\n",
    "user_ids = [user[\"user_id\"] for user in user_data]\n",
    "item_ids = [item[\"item_id\"] for item in item_data]\n",
    "\n",
    "user_id_to_index = {user_id: index for index, user_id in enumerate(user_ids)}\n",
    "item_id_to_index = {item_id: index for index, item_id in enumerate(item_ids)}\n",
    "\n",
    "print(user_id_to_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# Create user-item matrix\n",
    "num_users = len(user_ids)\n",
    "num_items = len(item_ids)\n",
    "\n",
    "user_item_matrix = np.zeros((num_users, num_items), dtype=np.float32)\n",
    "\n",
    "# Fill in the user-item matrix with 1.0 for liked items\n",
    "for user in user_data:\n",
    "    user_index = user_id_to_index[user[\"user_id\"]]\n",
    "    for item_id in user[\"liked\"]:\n",
    "        item_index = item_id_to_index[item_id]\n",
    "        user_item_matrix[user_index, item_index] = 1.0\n",
    "\n",
    "print(user_item_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KerasTensor(type_spec=TensorSpec(shape=(None, 1), dtype=tf.float32, name='input_15'), name='input_15', description=\"created by layer 'input_15'\")\n"
     ]
    }
   ],
   "source": [
    "# Define the matrix factorization model\n",
    "latent_dim = 10\n",
    "\n",
    "# Define input layers for user and item IDs\n",
    "user_input = tf.keras.layers.Input(shape=(1,))\n",
    "item_input = tf.keras.layers.Input(shape=(1,))\n",
    "\n",
    "# Create embeddings for users and items\n",
    "user_embedding = tf.keras.layers.Embedding(num_users, latent_dim)(user_input)\n",
    "item_embedding = tf.keras.layers.Embedding(num_items, latent_dim)(item_input)\n",
    "\n",
    "# Create embeddings for user and item biases\n",
    "user_bias = tf.keras.layers.Embedding(num_users, 1)(user_input)\n",
    "item_bias = tf.keras.layers.Embedding(num_items, 1)(item_input)\n",
    "\n",
    "# Calculate dot product of user and item embeddings\n",
    "dot_product = tf.keras.layers.Dot(axes=2)([user_embedding, item_embedding])\n",
    "\n",
    "# Add user and item biases to the dot product\n",
    "dot_product = tf.keras.layers.Add()([dot_product, user_bias, item_bias])\n",
    "\n",
    "# Create the recommendation model\n",
    "model = tf.keras.Model(inputs=[user_input, item_input], outputs=dot_product)\n",
    "\n",
    "print(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 739ms/step - loss: 0.9822 - val_loss: 1.0328\n",
      "Epoch 2/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9775 - val_loss: 1.0328\n",
      "Epoch 3/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9727 - val_loss: 1.0328\n",
      "Epoch 4/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9679 - val_loss: 1.0328\n",
      "Epoch 5/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9632 - val_loss: 1.0328\n",
      "Epoch 6/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9584 - val_loss: 1.0328\n",
      "Epoch 7/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9537 - val_loss: 1.0328\n",
      "Epoch 8/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9490 - val_loss: 1.0328\n",
      "Epoch 9/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9442 - val_loss: 1.0328\n",
      "Epoch 10/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9395 - val_loss: 1.0328\n",
      "Epoch 11/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.9348 - val_loss: 1.0328\n",
      "Epoch 12/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9300 - val_loss: 1.0328\n",
      "Epoch 13/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9253 - val_loss: 1.0328\n",
      "Epoch 14/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.9206 - val_loss: 1.0328\n",
      "Epoch 15/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9158 - val_loss: 1.0328\n",
      "Epoch 16/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.9111 - val_loss: 1.0328\n",
      "Epoch 17/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9063 - val_loss: 1.0328\n",
      "Epoch 18/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.9015 - val_loss: 1.0328\n",
      "Epoch 19/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8967 - val_loss: 1.0328\n",
      "Epoch 20/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8919 - val_loss: 1.0328\n",
      "Epoch 21/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8871 - val_loss: 1.0328\n",
      "Epoch 22/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8823 - val_loss: 1.0328\n",
      "Epoch 23/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8774 - val_loss: 1.0328\n",
      "Epoch 24/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8725 - val_loss: 1.0328\n",
      "Epoch 25/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8677 - val_loss: 1.0328\n",
      "Epoch 26/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8628 - val_loss: 1.0328\n",
      "Epoch 27/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8578 - val_loss: 1.0328\n",
      "Epoch 28/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8529 - val_loss: 1.0328\n",
      "Epoch 29/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8479 - val_loss: 1.0328\n",
      "Epoch 30/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8429 - val_loss: 1.0328\n",
      "Epoch 31/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.8379 - val_loss: 1.0328\n",
      "Epoch 32/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8329 - val_loss: 1.0328\n",
      "Epoch 33/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8279 - val_loss: 1.0328\n",
      "Epoch 34/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.8228 - val_loss: 1.0328\n",
      "Epoch 35/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.8177 - val_loss: 1.0328\n",
      "Epoch 36/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8126 - val_loss: 1.0328\n",
      "Epoch 37/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8074 - val_loss: 1.0328\n",
      "Epoch 38/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.8022 - val_loss: 1.0328\n",
      "Epoch 39/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7970 - val_loss: 1.0328\n",
      "Epoch 40/50\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7918 - val_loss: 1.0328\n",
      "Epoch 41/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7865 - val_loss: 1.0328\n",
      "Epoch 42/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7813 - val_loss: 1.0328\n",
      "Epoch 43/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7760 - val_loss: 1.0328\n",
      "Epoch 44/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7706 - val_loss: 1.0328\n",
      "Epoch 45/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7653 - val_loss: 1.0328\n",
      "Epoch 46/50\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7599 - val_loss: 1.0328\n",
      "Epoch 47/50\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.7545 - val_loss: 1.0328\n",
      "Epoch 48/50\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7490 - val_loss: 1.0328\n",
      "Epoch 49/50\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7436 - val_loss: 1.0328\n",
      "Epoch 50/50\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.7381 - val_loss: 1.0328\n",
      "[0, 0, 1, 1, 2]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "user_indices = [user_id_to_index[user[\"user_id\"]] for user in user_data for _ in user[\"liked\"]]\n",
    "item_indices = [item_id_to_index[item_id] for user in user_data for item_id in user[\"liked\"]]\n",
    "ratings = [1.0] * len(user_indices)\n",
    "\n",
    "history = model.fit(\n",
    "    [np.array(user_indices), np.array(item_indices)],\n",
    "    np.array(ratings),\n",
    "    epochs=50,\n",
    "    verbose=1,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "print(user_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_15 (InputLayer)       [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_16 (InputLayer)       [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " embedding_28 (Embedding)    (None, 1, 10)                30        ['input_15[0][0]']            \n",
      "                                                                                                  \n",
      " embedding_29 (Embedding)    (None, 1, 10)                90        ['input_16[0][0]']            \n",
      "                                                                                                  \n",
      " dot_7 (Dot)                 (None, 1, 1)                 0         ['embedding_28[0][0]',        \n",
      "                                                                     'embedding_29[0][0]']        \n",
      "                                                                                                  \n",
      " embedding_30 (Embedding)    (None, 1, 1)                 3         ['input_15[0][0]']            \n",
      "                                                                                                  \n",
      " embedding_31 (Embedding)    (None, 1, 1)                 9         ['input_16[0][0]']            \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 1, 1)                 0         ['dot_7[0][0]',               \n",
      "                                                                     'embedding_30[0][0]',        \n",
      "                                                                     'embedding_31[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 132 (528.00 Byte)\n",
      "Trainable params: 132 (528.00 Byte)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liked Items: {102, 103}\n",
      "Top 5 recommended items for user 1: [105, 109, 106, 108, 107]\n"
     ]
    }
   ],
   "source": [
    "# Make recommendations for a specific user (e.g., user_id = 1)\n",
    "user_id_to_recommend = 1\n",
    "user_index_to_recommend = user_id_to_index[user_id_to_recommend]\n",
    "user_embedding_weights = model.layers[2].get_weights()[0]\n",
    "# Access item embedding weights\n",
    "item_embedding_weights = model.layers[3].get_weights()[0]\n",
    "\n",
    "# # Get the top N recommended items\n",
    "\n",
    "top_n = 5\n",
    "# # Calculate the number of items\n",
    "num_items = len(item_ids)\n",
    "\n",
    "# # Ensure top_n does not exceed the number of items\n",
    "top_n = min(top_n, num_items)\n",
    "\n",
    "# Calculate predicted ratings for all items for the user\n",
    "user_ratings = np.dot(user_embedding_weights[user_index_to_recommend], item_embedding_weights.T)\n",
    "\n",
    "# Get the indices of items sorted by user ratings in descending order\n",
    "sorted_item_indices = np.argsort(user_ratings)[::-1]\n",
    "\n",
    "# Create a set of items that the user has liked for efficient lookup\n",
    "liked_items = set(user_data[user_index_to_recommend][\"liked\"])\n",
    "\n",
    "# Debug print to check liked_items\n",
    "print(\"Liked Items:\", liked_items)\n",
    "# Filter out items that the user has already liked\n",
    "# recommended_item_indices = [item_ids[i] for i in sorted_item_indices if item_ids[i] not in liked_items][:top_n]\n",
    "\n",
    "recommended_item_indices = [item_ids[i] for i in sorted_item_indices if item_ids[i] not in liked_items]\n",
    "\n",
    "top_item_indices = recommended_item_indices[:top_n]\n",
    "\n",
    "recommended_item_ids = [i for i in top_item_indices ]\n",
    "\n",
    "# Retrieve the actual item data for the recommended items\n",
    "# recommended_items_data = [item for item in item_data if item[\"item_id\"] in recommended_item_indices]\n",
    "\n",
    "# Get the corresponding item IDs for the top N recommended items\n",
    "# recommended_item_ids = [i for i in top_item_indices ]\n",
    "\n",
    "# print(f\"Top {top_n} recommended items for user {user_id_to_recommend}:\")\n",
    "# print(recommended_item_indices)\n",
    "\n",
    "print(f\"Top {top_n} recommended items for user {user_id_to_recommend}: {recommended_item_ids}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
